\chapter{无监督的自举式情感分类}
\label{ch4}

\section{引言}
\label{ch4_intr}
文本的情感分析是挖掘文本中主观性信息学的主要手段，是研究文本中观点、态度、情绪和立场等主观性信息是如何表达的。情感分析技术可以从数量庞大的文本数据中抽取并总结主观性信息，为后续的一些应用（商业智能（Business Intelligence），舆情分析（Public Opinion Analysis）或选举预测（Election Prediction）等）提供技术和工具支持\upcite{Liu2012}。在社交媒体中，一些基于文本的平台比如微博产生了大量针对各种话题或实体的带有主观性信息的数据。这对这些数据的分析，也就是情感分析正逐渐受到各个研究领域（比如推荐系统和搜索引擎）的重视。情感分析中一个主要的方法就是应用各种分类技术，也就是根据作者的主观态度将文本进行分类，一般将这种研究称为情感分类研究。情感分类一般是从一些标注过的训练数据中通过学习得到一个分类模型，学习得到能够将一种情感类型区别于其他类型的一些特征\upcite{LourencoJr2014}。这种模型的性能主要依赖于其能够学习到的数据中出现的情感的文本表达模式，一般是文本中出现的词语、短语或者词语的各种组合。情感分类也就是情感分析的分类形式，虽然可以被视作文本分类的特殊形式，实际上情感分类是比文本分类更具挑战的任务，因为文本中情感的表达方式严重依赖领域和上下文环境\upcite{jiang2011target,}。

随着微博（Twitter、新浪微博等）的出现和广泛使用，用户产生内容（UGC，User-Generated Content）成指数增长，这些内容并且这些内容对于我们来说是很容易获取的，并且这些内容里面有很多用户对于各种话题的观点和情感等主观性信息。因此我们可以很方便的从这些数据中提取出主观性信息，并使其在商业、旅游或者健康领域得到应用。但是对微博进行情感分类特别具有挑战性，因为（1）用户使用微博表达观点的方式是多种多样的，既有正规传统语言的表达方式，又有社交媒体特有的流行的表达方式，比如"coooooool", “OMG",":-("，“屌丝”，“逆袭”等，这些表达方式虽然对于人来说是比较直观和易于理解的，并且更加方便了用户的在线交流，但是对于计算机来说，却是很难准确确定这些表达方式的观点和情感等语义信息。（2）更具挑战性的是，因为用户群体的复杂性，经常会有用户创造出的一些缩写词或者新词，并且会将一些传统的词赋予新的语义在微博中重新使用，这些语言上的变化使得微博上观点的表达方式有别于传统文本的表达方式。综上所述，可以看出微博中的文本噪声、非正式本质以及语言词汇的急剧膨胀使得对微博中表达的主观性信息自动分析需要依赖于微博这种独特的语言环境，因此进行情感分类是困难的。这种情况被称为微博情感分类的领域（或语言环境）依赖问题，也就是使用其他文本数据集（比如评论或博客）训练出的分类器在微博的情感分类时会出现性能急剧下降，而要获得大量微博训练数据集需要大量的人力，并且微博数据具有时效性，不同时间阶段的微博数据集中观点表达方式也会产生漂移。

本章我们主要关注微博情感分类的领域依赖性问题。为了解决这个问题，基于我们的一些观察，我们提出了一种无监督的自举式（bootstrapping）情感分类框架。该框架首先使用现有的已经有情感标签的语言资源训练得到一个通用的能够跨领域使用的分类器；然后再根据该分类器的跨领域特点使用其作为初始分类器对微博进行分类，获得一些高可信度的微博作为训练集训练得到一个微博分类器；将两个分类器结合迭代使用共同训练（Co-training）过程，逐步在目标数据集扩展并训练微博分类器，直至其分类性能达到最优。

\section{相关工作}
\label{ch4_relt}
情感分类在观点挖掘研究中越来越受到重视，前期工作主要研究针对评论（商品或电影）进行情感分类。经常使用的方法可以分为基于规则的方法和基于学习的方法，其中基于机器学习方法性能一般比较好因而常被用来作为对表的标准\upcite{Pang2002}。

现在研究人员逐渐开始注意到微博中用户的主观性信息，并开始结合微博的语言特点进行对微博进行情感分类研究。一些研究显示可以将微博的一些独特的特征结合进情感分类方法中。比如，Barbosa和Feng~\upcite{Barbosa2010}提出了两阶段支持向量机分类器（Support Vector Machine (SVM) classifier）对tweet进行情感分类，证明了该分类其能对tweet的类别偏置（biased）和噪声具有很好的鲁棒性；Hu等~\upcite{Hu2013}将社交媒体数据中的情感表达解成情感指征（emotion indication）和情感关联（emotion correlation）两种信号，通过对两类情感信息进行联合建模方式实现了对微博的无监督情感分类；Jiang等~\upcite{jiang2011target}主要关注依赖于特定目标的微博情感分类，提出了通过将目标依赖特征（target-dependent features）和相关微博同时进行考虑的监督学习方法，并证明了可以提升情感分类性能；Wang等~\upcite{wang2011topic}针对hashtag级别的情感分类进行了研究，并提出了一个全新的图模型，然后使用提升（boosting）式分类方法进一步提高了模型的性能；Amir等~\upcite{AsiaeeT2012}针对单条微博的情感分类提出了一个分层分类器框架，框架通过抽取对特定目标的微博，将微博按情感类型分开以及分离正负情感类型微博三个层次进行有监督的分类学习；Hu等~\upcite{hu2013exploiting}基于社交理论抽取微博之间的情感关系，提出了一种全新的社会学方法使用这些情感关系以促进情感分类性能，并有效解决了数据中的噪声问题；同样受到社会学理论的启发，Guerra等~\upcite{CalaisGuerra2011}依据人类通常会持有一致的带有偏执的观点，提出了全新的迁移学习（transfer learning）方法解决微博基于话题的实时情感分类问题；Thelwall等~\upcite{Thelwall2010,Thelwall2012}设计了SentiStrength情感分析工具，用于对微博等社交媒体中非正式语言中的情感分析，该工具是基于规则的方法，使用了人工编辑的词典并结合了微博语言中的句法和拼写特点抽取微博中的情感强度，该工具获得了广泛的应用。

以上这些工作通过利用微博的一些网络和语言特点对情感分类方法进行了适应性的改进，以使得这些方法能够适用于微博语言环境，但是没有彻底解决微博情感分类问题的语言环境依赖问题，本章我们提出的方法从一个全新的视角来看情感分类问题，将情感分类的特征空间分各位环境依赖部分（context-dependent part）和环境独立部分（context-independent part）分别进行训练分类器，然后将两种分类器结合进一个自举式（bootstrapping）学习框架中。

\section{问题的形式化}
\label{ch4_form}
简单来说，情感分类主要目标就是将文本分类为预先定义的情感极性类别（一般是积极的，positive或消极的，negative）。形式化上，对于给定的文档语料库$ D=\lbrace d_{1},\dots ,d_{n} \rbrace$，预定义的情感类别$ Y=\lbrace 1,-1\mid \mathrm{positive}=1,\mathrm{negative}=-1 \rbrace$，情感分类的任务就是对每一个文档$ d_{i} $预测一个类别标签$ y_{i} $。为了与文本分类问题一致，每个文档可以表示为一个特征向量$ x=R^{n} $，$ n $表示特征空间的大小对于情感分类问题来说，对于每一个特征通常将其权重定为二值的，1表示特征在文档中出现，0表示没有出现\upcite{Pang2002}。对于有监督的机器学习，给定训练集$ D=\lbrace x_{1},\dots,x_{m} \rbrace $，可以学习到分类器：
\begin{equation}
\label{e1}
  f:D \longrightarrow Y, Y=\lbrace 1,-1 \rbrace \enspace .
\end{equation} 
对于未来文档$ x $，同样将其表示为特征向量$ x=\left( w_{1},\dots,w_{v} \right)  $（$ w_{i} $表示第$ i $维权重），就可以使用该分类器去预测其情感类别：$ f \left( x \right)   $。

在以往的情感分类研究中，有一个潜在的假设，就是用于表示文本的特征向量中所有的特征（一般是词语）在表达情感极性时作用是相同的，也就是其出现与否可以在所有的文本中表达相同的情感。实际上这种假设是不成了立的，因为有些词语表达的是客观信息，有些表达主观信息，而且即便是表达主观信息，作用也都不一样。因为有些词语无论用在那种领域或语境下都能表达同样的情感，而有些词语只能在某些具体的语境下表达某种情感。以下面这条微博为例：

\begin{description}
\item{tweeet:} @Kid\_Cloudz: Happy birthday to Yessicaaaa! :D lovee you feggit wish you the best day everrrrr!!!!! @030268.
\end{description}

以词袋模型（bag-of-words）为例，所有的词语都应该抽取出来作为特征加入到特征向量中同等地用于对这条微博的情感倾向进行建模。然而，仔细观察就会发现，微博中有些词语（@Kid\_Cloudz, :D, lovee, everrrrr,!!!!!）实际上只能在微博这种语境中出现并且表达出某种情感倾向，而另外一些词语（Happy, birthday, wish, best, thanks）无论在什么领域或语境下都是正面情感倾向的的标识。基于这样的直观认识，我们可以提出以下特征空间划分的假设：

\begin{theorem}[假设]
\textbf{特征空间划分假设：} 对于微博情感分类问题的特征向量空间，可以将其所有的特征划分为以下两个部分：
\begin{itemize}
\item{领域独立部分：}也就是通用的特征，该部分特征在任何领域和语言环境下都是某种情感倾向的表达方式。
\item{领域依赖部分：}也就是具体语言特征，这部分特征只有在微博这种语言环境下才能有具体的语义和表达一定的情感倾向。
\end{itemize}
\end{theorem}
这个假设可以更加形式化的表示，对于情感分类问题中一条微博的特征向量$ x=\left(  w_{1},\dots,w_{l},w_{l+1},\dots,w_{v} \right) $，可以划分为两个部分：

\begin{equation}
\label{e2}
x=\left\{
\begin{array}{rcl}
x_{g}     & \qquad        &:\mbox{general features}\\
x_{c}     &  \qquad       &:\mbox{context features}
\end{array}
\right. \enspace .
\end{equation}
其中，$ x_{g}= \left( w_{1},\dots,w_{l}\right) $是特征向量空间的通用部分，而$ x_{c}= \left( w_{l+1},\dots,w_{v}\right) $是领域依赖部分。

基于以上假设，情感分类问题可以进一步形式化定义为：

\begin{definition}[情感分类]
根据假设（1），情感分类问题可以表示为$(X_{g},X_{c},Y)$，其中：
\begin{itemize}
\item $ X_{g}\subset R^d$和$ X_{c}\subset R^p$为两个输入特征空间，$d+p=n$，分别表示两部分空间的维度;
\item $Y$为输出空间，一般表示为二值空间$ Y=\lbrace 1,-1\mid \mathrm{positive}=1,\mathrm{negative}=-1 \rbrace$;
\item 假设有一独立同分布（independently identically distributed）微博实例集合$D=\{(x_i^g,x_i^c,y_i);i=1\ddots m\}$，该集合是从空间$P=X_g \times X_c \times Y$中采样得到，向量$x_i^g$表示实例领域独立部分特征，向量$x_i^c$表示领域依赖部分特征，$y$表示实例微博的情感类别；
\end{itemize}
实际上经过特征空间的划分提供了对于同一微博的两种不同的视角（view），因此可以将数据集$D$看作是$D_g=\{(x_i^g,y_i);i=1\ddots m\} \in (X_g \times Y)^m$和$D_c=\{(x_i^c,y_i);i=1\ddots m\} \in (X_c \times Y)^m$两种不同的集合，因此对于集合$D$的情感分类问题可以视为构建两个分类器通用情感分类器（General Sentiment Classifier）和微博情感分类器（Context Sentiment Classifier）：
\begin{equation}
\begin{cases}
General Sentiment Classifier:f_g:X_g \mapsto Y\\
Context Sentiment Classifier:f_c:X_C \mapsto Y
\end{cases}
\end{equation}
\end{definition}
当然基于部分特征空间的分类器性能上是否会降低还是一个值得研究的问题，但是本章我们主要研究以下几个问题：
\begin{enumerate}
\item 对于从实例中抽取到的同一个特征空间，怎么确定特征空间中领域依赖和领域独立两部分特征？
\item 得到不同的特征空间后，使用什么样的训练数据集来训练得到两个不同的分类器？
\item 两种独立的分类器比同一空间分类器性能上会有什么样的变化，如何将两种分类器结合起来达到更好的性能？
\end{enumerate}

\section{无监督的情感分类框架}
\label{ch4_frame}
在微博语言中，除了正规的表达方式方式外，一些语言因为比较难以理解而常被视为“火星文”，尤其是对于不长使用微博的人来说对于一条微博中出现的一词语可能不理解其语义。但是整条微博的情感倾向性确能够比较容易读懂，因为微博常常是正规表达方式和“火星文”混合在一起使用的，理解了正规表达部分，也就能理解了整条微博的情感倾向。直观上，这种现象可以通过我们的特征空间分割假设来解释，正规表达部分特征也能从一个不同的视角（view）来阐释整条微博的主观情感。而这些正规表达部分特征$ x_{g} $是不以来于微博语境的，对于任何人（长使用微博的或是很少使用微博的）都是易于理解的。

相似的，对于微博的自动情感分类，基于我们特征空间分割假设，可以认为一条微博的情感倾向性可以通过两部分特征都识别出来。也就是说，如果能够对与一些通用的情感表达知识，在某种程度上也能识别出一条微博的情感极性（根据微博中正规表达方式的比例不同，比例越大就越容易识别）。实际上有很多研究者已经开始研究如何建立各种情感词汇表来对这种通用的情感知识进行建模了，比如我们前面章节的工作中提到的OpinionFinder词典\upcite{Wilson2005,Wilson2009}、ANEW词典\upcite{Bradley1999}、AFINN词典\upcite{Nielsen2011}、SentiWordnet\upcite{Esuli2006}、HowNet情感词典\upcite{2013}，NTUSD情感词典\upcite{Ku2007}、情感词汇本体词库\upcite{2013a}以及我们的SentiHowNet\upcite{谢松县2014}。虽然这些词典在尝试着建立通用的情感表达知识库，但是由于存在一词多义现象，使得一个词语的具体情感倾向性还是需要具体的语言上下文进行“消歧”。因此能够真正找到通用的资源来对跨领域情感知识进行建模不是一件容易的事。但是这样的知识资源却是存在的，比如成语和谚语等具有明确无歧义的情感倾向性，如何能够利用这样的知识资源对通用情感知识进行建模是本章研究的重点。

\subsection{通用情感分类器}
\label{general}
在语言资源中有许多对情感分类研究非常有用的资源，其中成语资源就是其中之一。成语（或谚语，本章中用成语通指这两种语言资源）无论在中文还是英文中都存在，比如中文的“空中楼阁”、英文的``bring down the house''（搏得满堂喝彩）等。这些成语的情感倾向性是固定不变的，不会随着领域或语境的不同而有歧义。这与我们的通用情感分类器需求十分契合，实际上有很多的专门针对成语编辑的词典资源，为通用情感分类器提供了很好的数据集进行训练。一般的成语词典的条目如下所示：
\begin{description}
\item{空中楼阁：}贬义词，形容虚构的事物或不现实的理论、方案，脱离实际的理论、计划及空想。
\end{description}
在“空中楼阁：”条目中，有三部分组成：成语本身、情感倾向性（贬义，属消极情感）以及该成语的释义部分。其中释义部分有几个同
There are many linguistic resources highly valuable for sentiment classification, of which idiom resources attract interests of this research. 
Idioms are common phenomena of many languages beside Chinese, such as ``castles in the air'', ``a bed of thorns'', and ``bring down the house'' in English.
As is convinced, the sentimental polarity of idioms is independent and unchangeable under any context. 
There are many off-the-shelf idiom lexicons in all kinds of languages with entries taking the example form as:

\textit{castles in the air: a derogatory term, indicate the illusive things or impractical fanciness metaphorically.}

In this example, the entry is composed of three parts: the idiom ``castles in the air'', the semantic orientation ``a derogatory term'' representing negative
sentimental polarity and a short paraphrase with three general negative words (``illusive, impractical and fanciness''). 
The example provides us with a labelled sentimental instance with general sentiment features and a negative label.
Most importantly, the sentimental polarity of such instance is independent of any context just as the idiom it explains. 
Based on such observation, another hypothesis is proposed as follows:
\begin{hypothesis}
\label{h2}
The sentimental polarity of the idiom paraphrase is independent of language context just as the idiom it describes.
\end{hypothesis}
With Hypothesis~\ref{h2} admitted, we could constructed a training dataset with the features extracted from paraphrases of idioms as general feature vector, the sentimental polarity of idioms as sentimental labels. 
Then a context-independent classifier could be trained to model the general sentiment knowledge.

\subsection{Context Sentiment Classifier}
\label{context}

As the general sentiment features are only one part of all features in the whole feature space, the other context-dependent part of features should be considered in order to capture the subtle clues embedded in the specific sentiment expressions in language context of microblogs.

To model the context-dependent part of tweets, there are two questions must be solved. 
The first is to identify the context-dependent part of features extracted from tweets. 
In fact, new expressions appears on microblogs with the explosively increasing of UGC, which makes it rather difficult to clearly tell whether each word is context dependent or not. 
However tweets are conventionally short with the limitation of 140 characters, and users often express one particular sentiment in one tweet with a few words. 
Based on the particular characteristics of tweets, we make an assumption that if a tweet contains idioms,  sentimental polarity of words in a tweet are often context-dependent except for the idioms. 
The second is how to find labelled instances to train the context-dependent classifier. 
Some researchers have proposed distant supervision to solve the training data shortage of Twitter \cite{xsongx:b36,xsongx:b37}. 
In this paper we establish our training dataset in a similar way.
We retrieve tweets on microblogs and try to get as many tweets as possible that contains idioms. 
By stripping off idioms, we extracted context-dependent features from left words, and took the sentimental polarity of idioms as labels. 
So we get our noisy labelled dataset and a context-dependent classifier is trained to model the context-dependent knowledge.

\subsection{Combination of Two Classifiers}
\label{combination}

Although theoretically the general classifier and context classifier could be able to model different sentiment knowledge separately and classify the sentiment of a tweet accurately to some extent, the coverage and efficiency of them are limited by the quality and quantity of training datasets. 
Besides, it is obvious that the paraphrase of idiom and tweet segments (lefts by stripping off idioms) is usually very short, so the feature vectors of datasets must be very sparse, which degrades the performance of the classifiers. 
For above reasons, a consistent bootstrapping machine learning framework is chosen to combine the two classifiers together. 
The framework is illustrated in Figure~\ref{fig1}. 
\begin{figure*}[!t] 
\centering%
\includegraphics[width=6.0in,height=2.8in]{itse13p.pdf}
\caption{The Bootstrapping Sentiment classification Framework}
\label{fig1}
\end{figure*}
As illustrated in the framework, in an iterating manner, the general classifier $ P_{g} $ and context classifier $ P_{c} $ are applied to test dataset so that the every test instance $ x_{i} $ is predicted labels $ c_{i}=\lbrace c_{g},c_{c}\rbrace $ initially, with confidence $ p_{i}= \lbrace p_{g},p_{c}\rbrace$. 
Then a combined confidence score is calculated with Equation~\ref{e3}:
\begin{equation}
\label{e3}
p_{i}=\left\{
\begin{array}{rcl}
\lambda\ast p_{g} + \left( 1-\lambda \right) \ast p_{c} \qquad \mbox{if} \quad c_{g}=c_{c};\\
0 \qquad \mbox{if} \quad c_{g} \neq c_{c};
\end{array}
\right. \enspace .
\end{equation}
where $ \lambda $ is the coefficient to control impacting weights of different part of features. 
We initialize $ \lambda = 0.5 $ with equal weights of general part and context part of features, and to make combined classifier more adaptable for microblogs, we  increase the weight of context part step by step with the bootstrapping iteration progressing.
The test dataset initially labelled as $ c_{i} \left( c_{i} \in \lbrace 1, -1\rbrace \right)$ was sorted with descending confidence $ p_{i} \left( p_{i} \neq 0 \right) $ for two sentimental categories $ C=\lbrace 1,-1\rbrace $ separately.
The $ n $  positive and negative instances with top high confidence are selected as new instances to add into the training dataset and improve the context classifier to a more context-aware classifier. 
Such a procedure iterates until convergence.
The output of such semi-supervised sentiment classification framework is the predicted results of test dataset. 
Above all, the whole framework can combine the two classifiers which constructed on divided feature space into a stronger classifier. 

\subsection{Classifier Description}
\label{classifier}

We adopt the same methods as Pang et al.~\cite{xsongx:b4}, in that they have applied Na\"\i ve Bayes, Maximum Entropy and Support Vector Machine classifiers to identify the effectiveness of machine learning techniques on sentiment classification, and they got satisfying result (accuracy of 82.9\%).
\subsubsection{Na\"\i ve Bayes Classifier.}
\label{bayes}
Naïve Bayesian classifier is the most popular text classification techniques.
For sentiment classification problem as formulated in Section~\ref{formulation}, to determine which sentimental category $ c_{j} $ a document $ d_{i} $ belongs to, it is needed to compute the posterior probability $ P \left(c_{j} \mid d_{i} \right)$. 
According to the Bayesian probability and the multinomial model, based on the hypothesis that the probabilities of features $ w_{d_{i},k} $ are independent given document class, Equation~\ref{e4} is got:
\begin{equation}
\label{e4}
P \left(c_{j} \mid d_{i} \right) = \frac{P \left( c_{j} \right)\prod_{k=1}^{| d_{i} |} P \left( w_{d_{i},k} \mid c_{j} \right)}{\sum_{r=1}^{|C|}P \left( c_{r} \right)\prod_{k=1}^{| d_{i} |} P \left( w_{d_{i},k} \mid c_{r} \right)} \enspace .
\end{equation}
The class with the highest probability is assigned as the sentimental category of the document $ d_{i} $. 
\subsubsection{Maximum Entropy Classifier.}
\label{entropy}
The Maximum Entropy classifier assigns the class with the higher conditional probability to the sentimental category of document $ d_{i} $ as follows:
\begin{equation}
\label{e5}
P \left( c_{j} \mid d_{i}, \overrightarrow{\theta} \right) = \frac{1}{Z}exp \left( \overrightarrow{\theta}, \overrightarrow{f} \left( d_{i},c_{j} \right) \right) \enspace .
\end{equation}
where $ \overrightarrow{\theta} $ denotes the vector of feature weights, $ \overrightarrow{f} \left( d_{i}, c_{j} \right)$ denotes feature function that maps pair $ \left( d_{i}, c_{j} \right) $ to a feature vector, and $ Z $ denotes normalization factor.
With labelled dataset $ D $, the training procedure is trying to solve such an optimization problem as:
\begin{equation}
\label{e6}
\overrightarrow{\theta^{\ast}}=argmax_{\overrightarrow{\theta}}\prod_{i=1}^{|D|} P \left( c_{j} \mid d_{i}, \overrightarrow{\theta} \right) \enspace .
\end{equation} 
\subsubsection{Support Vector Machine Classifier.}
\label{svm}
Support Vector Machines classifier (SVM), is a kind of discriminative method of machine learning techniques.
SVM tries to find a decision surface to separate the training data into two classes and makes decisions based on support vectors. 
In this research, linear SVM has been adopted due to its popularity and sound performance in sentiment classification task.
The training of SVM is trying to minimize an constraint optimization problem:
\begin{equation}
\label{e7}
\begin{aligned}
\overrightarrow{\alpha^{\ast}}=argmin \left( -\sum_{i=1}^{n}\alpha_{i} + \sum_{i=1}^{n} \sum_{j=1}^{n}\alpha_{i}\alpha{j} x_{i}x_{j}<\overrightarrow{x_{i}},\overrightarrow{x_{j}}> \right)\\
\mbox{Subject to:} \sum_{i=1}^{n}\alpha_{i}y_{i}=0 , 0\leqslant \alpha_{i} \leqslant 1
\end{aligned} \enspace .
\end{equation}

\section{Experiment}
\label{experiment}

In this section, the proposed semi-supervised sentiment classification framework is verified in an empirical test. 
The test has been carried out with Chinese dataset constructed from an off-the-shelf on-line idiom dictionary and microblog platform Tencent\footnote{\url{http://t.qq.com/}}. 

\subsection{Experiment Description}
\label{description}

\paragraph{Dataset}
We crawled the on-line idiom dictionary from China Education Network\footnote{\url{http://chengyu.teachercn.com}} and got an idiom dataset of 8,160 instances labelled with positive (3,648 instances) and negative (4,512 instances) sentiment, which was used to train the general classifier. 
From Apr.15th,2013 to May 1st,2013, we monitored Tencent time-line tweet streams, retrieved and extracted the tweets that contained at least one idiom in our idiom dataset, resulting in about 120,346 tweets. 
After stripping off idioms from all tweets and removing tweets with characters less than 4, we got a dataset of 91,268 instances which was used to train context classifier. 
The dataset from the First Chinese tweet Sentiment Analysis and Semantic Relationship Extraction Evaluation of CCF Natural Language Processing and Chinese Computing\footnote{\url{http://tcci.ccf.org.cn/conference/2012/pages/page04_eva.html}} was used to evaluate performance of our framework. 
\paragraph{Classifiers and performance measurement}
There are various complicated measurements to evaluate the performance of computational algorithm, of which the simplest accuracy index was chosen to evaluate the performance of our framework, because the comparison between measurements was not the important points of our research. 
As for classifiers, Na\"\i ve Bayes classifier and Maximum Entropy classifier of NLTK (Natural Language ToolKits) \cite{xsongx:b27} package and Support Vector Machine classifier of Libsvm \cite{xsongx:b28} package were used for classification. 
All the parameters and settings were optimized by cross-validation.
\paragraph{Baseline and upper bound}
Two baselines were used to compare with the proposed framework, the first one was na\"\i ve $ 50\% $ baseline since the test dataset was balanced with respect to the sentiment classes, the other one was the traditional lexicon-based classifier by comparing the number of positive words and negative words in HowNet sentiment lexicon for a tweet to determine its sentiment class.
As mentioned in Section~\ref{related}, supervised machine learning methods are often used as upper bound to be compared by other methods. 
In the experiments, an upper bound was also set up with test dataset in the five-folded cross-validation manner.
\paragraph{Preprocessing}
Text written in Chinese are not well formatted in that words in a sentence are not separated by space as English. 
All the text in Chinese must be segmented before bag-of-words features being extracted. 
In the experiment, all text of training and testing dataset were segmented with Chinese segmentation software ICTCLAS\footnote{\url{http://ictclas.nlpir.org/}}.

\subsection{Result and Analysis}
\label{result}
To determine the values of $ \lambda $ in Equation~\ref{e3}, we carried out traversal experiment by varying the value of $ \lambda $ from $ 0 $ to $ 1 $ with step of $ 0.1 $. The result is illustrated in Figure~\ref{fig2}.
\begin{figure}[!t]
\centering
\includegraphics[width=3.5in,height=2.0in]{lambda.pdf}
\caption{The Impact of $ \lambda $ on Different Classifiers: NB denotes Na\"\i ve Bayes, MX denotes Maximum Entropy and SVM denotes Support Vector Machine.}
\label{fig2}
\end{figure}
The values of $ \lambda $ for each combined bootstrapping classifier based on three different classifiers are fixed as the accuracy reaches its peak, which are: $ 0.4 $ for Na\"\i ve Bayes classifier, $ 0.5 $ for Maximum Entropy classifier, and $ 0.3 $ for Support Vector Machine classifier.

The final sentiment classification results are shown in Table~\ref{t1}. 
\begin{table}[!t]
\caption{Results for Different Classifiers}
\label{t1}
\centering
\begin{tabular}{|l||l|l|l|}
\hline
%\noalign{\bigskip}
\bfseries Classifier &  \bfseries NB    &   \bfseries MX    &   \bfseries SVM    \\
%   & Lexicon  & Supervised & General & Context &  Combined \\
%\noalign{\bigskip}
\hline
%\noalign{\bigskip}
\bfseries Lexicon Classifier & 0.725 & 0.725 & 0.725 \\
\hline
\bfseries Supervised Classifier & 0.785 & \textbf{0.806} & 0.826 \\
\hline
\bfseries General Classifier & 0.734 &  0.740 & 0.762 \\
\hline
\bfseries Context Classifier & 0.766 & 0.785 & 0.805 \\
\hline
\bfseries Combined Classifier & \textbf{0.802} & 0.802 & \textbf{0.843} \\
% NB & 0.725 & 0.785 & 0.714 & 0.766 & \textbf{0.802}   \\
% MX & 0.725 & \textbf{0.806} & 0.740 & 0.785 & 0.802  \\
% SVM & 0.725 & 0.826 & 0.722 & 0.805 & \textbf{0.843} \\
%\noalign{\bigskip}
\hline
\end{tabular}
\end{table}

Firstly, the accuracies of general classifier and context classifier all surpass the na\"\i ve baseline (50\%), which proves that they are superior to random selection and may be better choice when there are no labelled dataset available for supervised or semi-supervised machine-learning sentiment classification.

Secondly, the accuracy of general classifier is a little higher than the traditional lexicon-based classifier, in that although they can both model the general sentiment knowledge, the general classifier is trained on context-independent part of features, so it can better catch the holistic sentimental polarity of tweets, while the sentiment lexicon often contains ambiguous entries. 
As for the context classifier, the performance outperforms the traditional lexicon-based classifier and general classifier, because it has been trained on context-aware part of features, and the users are more willing to express their sentiment with ``Mars Language'' of microblogs, so the context classifier is more adaptable for microblog context.

Finally, the combined classifier shows the best performance by combining general classifier and context classifier. 
It even outperforms the upper bound supervised classifier, which proves the effectiveness our proposed framework because it can not only catch the holistic sentimental polarity of tweets by modelling general sentiment knowledge but also adapt to the microblog language context by considering the subtle sentiment expressions articulated in tweets.

\section{Conclusion}
\label{conclusion}

Context-dependent problem has always been a main challenge of sentiment classification.
In this paper, we have proposed a novel semi-supervised framework to get it solved in the microblog language context. 
From a different perspective of feature space, we put forward the assumption that feature space can be divided into the general part and the context part.
To make use of two parts of features, two classifiers are trained on dataset constructed from idiom resources and tweets separately. 
Our framework combines the classifiers with a semi-supervised bootstrapping learning algorithm. 
The experiment results show that the proposed framework could outperform the state-of-art supervised classifier. 
In future, we will try to improve the sentiment classification performance by enlarging the context-independent resources and extracting richer features besides bag-of-words feature.